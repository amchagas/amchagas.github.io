---
title: "Beyond GLMs: A Generative Mixture Modeling Approach to Neural System Identification"
collection: publications
permalink: /publication/2013-11-21-GLM-paper
excerpt: 'Generalized linear models (GLMs) represent a popular choice for the probabilistic characterization of neural spike responses. While GLMs are attractive for their computational tractability, they also impose strong assumptions and thus only allow for a limited range of stimulus-response relationships to be discovered. Alternative approaches exist that make only very weak assumptions but scale poorly to high-dimensional stimulus spaces. Here we seek an approach which can gracefully interpolate between the two extremes. We extend two frequently used special cases of the GLM—a linear and a quadratic model—by assuming that the spike-triggered and non-spike-triggered distributions can be adequately represented using Gaussian mixtures. Because we derive the model from a generative perspective, its components are easy to interpret as they correspond to, for example, the spike-triggered distribution and the interspike interval distribution. The model is able to capture complex dependencies on high-dimensional stimuli with far fewer parameters than other approaches such as histogram-based methods. The added flexibility comes at the cost of a non-concave log-likelihood. We show that in practice this does not have to be an issue and the mixture-based model is able to outperform generalized linear and quadratic models.'
date: 2013-11-21
venue: 'PLOS Computational Biology'
paperurl: 'https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003356'
citation: 'Your Name, You. (2013). &quot;Paper Title Number 2.&quot; <i>Journal 1</i>. 1(2).'
---
Generalized linear models (GLMs) represent a popular choice for the probabilistic characterization of neural spike responses. While GLMs are attractive for their computational tractability, they also impose strong assumptions and thus only allow for a limited range of stimulus-response relationships to be discovered. Alternative approaches exist that make only very weak assumptions but scale poorly to high-dimensional stimulus spaces. Here we seek an approach which can gracefully interpolate between the two extremes. We extend two frequently used special cases of the GLM—a linear and a quadratic model—by assuming that the spike-triggered and non-spike-triggered distributions can be adequately represented using Gaussian mixtures. Because we derive the model from a generative perspective, its components are easy to interpret as they correspond to, for example, the spike-triggered distribution and the interspike interval distribution. The model is able to capture complex dependencies on high-dimensional stimuli with far fewer parameters than other approaches such as histogram-based methods. The added flexibility comes at the cost of a non-concave log-likelihood. We show that in practice this does not have to be an issue and the mixture-based model is able to outperform generalized linear and quadratic models.

[Download paper here](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003356)


Theis, Lucas, Andrè Maia Chagas, Daniel Arnstein, Cornelius Schwarz, and Matthias Bethge. 2013. ‘Beyond GLMs: A Generative Mixture Modeling Approach to Neural System Identification’. PLOS Computational Biology 9 (11): e1003356. https://doi.org/10.1371/journal.pcbi.1003356.
